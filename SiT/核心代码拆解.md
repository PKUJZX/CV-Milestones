### models.py

#### 1. 辅助函数 `modulate`

```Python
def modulate(x, shift, scale):
    return x * (1 + scale.unsqueeze(1)) + shift.unsqueeze(1)
```

这个函数是实现自适应层归一化（Adaptive Layer Normalization, adaLN）的核心操作。它接收一个输入张量`x`，以及从条件信息（时间和类别）中生成的`shift`（偏移）和`scale`（缩放）两个向量。

- **作用**: 动态地调整输入`x`的均值和方差。这是一种非常高效的条件注入方式，它允许模型根据不同的时间步`t`和类别`y`来改变其内部激活值的状态，从而精细地控制生成过程。
- `unsqueeze(1)`: 这个操作是为了将`shift`和`scale`的维度扩展，使其能够与更高维的输入`x`（通常是 `[batch_size, num_patches, hidden_size]`）进行广播运算。

#### 2. 条件嵌入模块 (Conditional Embedding)

生成模型的好坏很大程度上取决于它如何理解和使用条件信息。SiT模型主要使用两种条件：**时间步（Timestep）** 和 **类别标签（Label）**。

##### `TimestepEmbedder`

这个模块负责将一个标量时间步 `t` (例如，从0到1之间的一个浮点数) 转换成一个高维向量，以便神经网络能够处理。

- **`timestep_embedding` (静态方法)**: 这是将时间`t`向量化的第一步。它使用了和原始Transformer论文中位置编码相同的**正弦/余弦频率编码**方法。
  - 它为不同的维度创建不同频率的`sin`和`cos`波。
  - 这种编码方式使得模型能够轻易地通过线性变换来推断出不同时间步之间的相对关系，例如，模型可以“感知”到`t=0.2`和`t=0.3`是相近的。
- **`mlp` (多层感知机)**: 将频率编码后的向量通过一个简单的两层MLP（`Linear -> SiLU -> Linear`）进行非线性变换，最终生成一个维度为`hidden_size`的嵌入向量`t_emb`。这个`t_emb`就包含了模型在特定时间步`t`所需要的所有信息。

##### `LabelEmbedder`

这个模块负责将离散的类别标签（例如，ImageNet中的1000个类别，索引从0到999）转换成高维向量。

- **`embedding_table`**: 这是一个标准的`nn.Embedding`层。你可以把它想象成一个大型查询表，每个类别索引对应表中的一行（一个`hidden_size`维的向量）。
- **Classifier-Free Guidance (CFG) 支持**: 这是该模块的一个关键特性。
  - `use_cfg_embedding = dropout_prob > 0`: 如果类别丢弃概率`dropout_prob`大于0，嵌入表的大小会增加1（`num_classes + 1`）。这个额外的索引（第1000号）专门用于表示“无条件”或“空”类别。
  - `token_drop`: 在训练期间，该函数会以`dropout_prob`的概率随机地将某些样本的真实标签替换为这个“空”类别标签。
  - **目的**: 这样一来，模型在训练时就同时学会了**有条件生成**（“请画一只猫”）和**无条件生成**（“随便画点什么”）。在推理时，我们可以利用这两者之间的差异来加强条件信号，从而生成质量更高、与文本提示更相关的图像。

#### 3. 核心构建块: `SiTBlock`

这是SiT模型的主干，是堆叠起来构成整个网络深度的核心模块，它本质上是一个带有**自适应条件注入**功能的Transformer块。

- **结构**: `LayerNorm -> Attention -> LayerNorm -> MLP`，这是标准的后归一化（Post-Norm）Transformer块结构。
- **`adaLN_modulation`**: 这是`SiTBlock`的“大脑”。它是一个简单的`SiLU -> Linear`网络，接收组合后的条件向量`c = t_emb + y_emb`作为输入。
  - 它的输出是一个`6 * hidden_size`维度的巨大向量。
  - `chunk(6, dim=1)`: 这个向量被切分成6个部分，分别对应多头自注意力（MSA）和MLP层前所需的`shift`, `scale`, 和 `gate`。
- **条件注入的流程**:
  1. 输入`x`先进过`norm1`层进行归一化。
  2. 归一化后的`x`被`modulate`函数使用`shift_msa`和`scale_msa`进行动态调整。
  3. 调整后的`x`送入`self.attn`（多头自注意力）层进行计算。
  4. 注意力层的输出被一个`gate_msa`向量进行缩放，然后通过残差连接加回到原始的`x`上。`gate`参数让模型可以学习在不同条件下，是更多地依赖注意力块的输出，还是更多地依赖原始输入。
  5. 对MLP层重复同样的过程（`norm2 -> modulate -> mlp -> gate -> residual`）。

这种设计使得条件信息`c`能够深度、精细地控制每一层Transformer的信息流，而不是像传统模型那样只在输入层注入一次。

#### 4. 输出层: `FinalLayer`

在经过所有`SiTBlock`的处理后，`FinalLayer`负责将最终的特征向量转换回潜在空间（latent space）的图像格式。

- **结构**:
  1. `norm_final`: 最后一层自适应层归一化，同样接收条件`c`来生成`shift`和`scale`。
  2. `linear`: 一个线性层，将`hidden_size`维的特征向量投影回`patch_size * patch_size * out_channels`的维度。这个维度正好对应一个图块（patch）所需的全部像素信息。

#### 5. 主模型: `SiT`

这是将上述所有模块组装在一起的最终模型。

- **初始化 `__init__`**:
  - **参数**: 接收模型尺寸、图块大小、通道数、类别数等超参数。
  - **`x_embedder`**: `PatchEmbed`层，负责将输入的潜在空间图像`z`（例如 `32x32x4`）切割成一系列图块（patches），并将每个图块线性投影成`hidden_size`维的向量。
  - **`t_embedder` 和 `y_embedder`**: 实例化之前定义的条件嵌入模块。
  - **`pos_embed`**: 2D正弦/余弦位置编码。这是一个不可训练的参数，用于向模型提供每个图块的空间位置信息。
  - **`blocks`**: 一个`nn.ModuleList`，包含了`depth`个`SiTBlock`实例，构成了模型的主体。
  - **`final_layer`**: 实例化最终的输出层。
  - **`initialize_weights`**: 调用一个专门的函数来对模型的权重进行细致的初始化。良好的初始化对大型Transformer的稳定训练至关重要。例如，它将`adaLN_modulation`中最后一个线性层的权重初始化为0，这样在训练初期，条件注入的作用较小，使得训练更加稳定。
- **前向传播 `forward(self, x, t, y)`**:
  1. `x = self.x_embedder(x) + self.pos_embed`: 将输入`x`分块、嵌入，并加上位置编码。
  2. `t = self.t_embedder(t)` 和 `y = self.y_embedder(y, self.training)`: 分别获取时间和类别的嵌入向量。
  3. `c = t + y`: 将时间和类别嵌入向量相加，形成统一的条件向量`c`。这是一种简单而有效的融合方式。
  4. `for block in self.blocks: x = block(x, c)`: 将数据和条件向量`c`送入堆叠的`SiTBlock`中进行核心处理。
  5. `x = self.final_layer(x, c)`: 通过最终层得到输出。
  6. `x = self.unpatchify(x)`: 将图块化的向量序列重新组合成潜在空间图像的格式（例如 `[batch, channels, height, width]`）。
  7. `if self.learn_sigma: x, _ = x.chunk(2, dim=1)`: 如果模型被设计为同时预测噪声和方差（`learn_sigma=True`），则输出通道数会加倍。这一步是将预测结果切分，只返回主要的部分（通常是预测的噪声或速度）。
- **带CFG的前向传播 `forward_with_cfg(...)`**:
  - 这个函数专门用于推理和采样。它接收一个`cfg_scale`参数，控制条件引导的强度。
  - **核心逻辑**: 它将输入`x`在batch维度上复制一份，然后调用`self.forward`进行一次计算。此时的输入`y`包含了有条件和无条件两部分的标签。得到的`model_out`也因此包含了有条件预测`cond_eps`和无条件预测`uncond_eps`。
  - `half_eps = uncond_eps + cfg_scale * (cond_eps - uncond_eps)`: 这就是CFG的数学公式。它以无条件预测为基准，在“有条件方向”（`cond_eps - uncond_eps`）上移动`cfg_scale`倍的距离，从而得到最终的、被引导的预测结果。

#### 6. 模型创建工厂: `create_SiT_model`

这是一个非常实用的工厂函数，它允许用户通过一个简单的字符串（如`"SiT-XL/2"`）来方便地创建预定义好尺寸的SiT模型。

- 它解析字符串来获取模型尺寸（`XL`）和图块大小（`2`）。
- 在一个字典`size_configs`中预存了不同尺寸（S, B, L, XL）对应的深度、隐藏层大小和注意力头数。
- 这样就无需在创建模型时手动输入一长串复杂的参数，大大提高了代码的可用性和可读性。



### transport.py

这个文件的核心任务是**定义和管理从一个简单分布（随机噪声）到一个复杂分布（真实图像）的“路径”或“变换过程”**。它负责两件大事：

1. **训练时**: 计算模型在学习这个变换过程中产生的损失。
2. **采样时**: 利用学成的模型，引导一个随机噪声点沿着这条路径“行走”，最终变成一张清晰的图像。

#### 1. 辅助函数

```python
def mean_flat(x):
    return torch.mean(x, dim=list(range(1, len(x.size()))))

def expand_t_like_x(t, x):
    return t.view(t.size(0), *([1] * (len(x.size()) - 1)))
```

- `mean_flat(x)`: 这是一个方便的工具函数，用于计算一个批次（batch）中每个样本的损失的平均值。它将除了批次维度（`dim=0`）之外的所有维度（通道、高、宽）都展平并求均值。
- `expand_t_like_x(t, x)`: 将一个一维的时间向量 `t`（形状为 `[batch_size]`）扩展成与高维图像张量 `x`（形状为 `[batch_size, channels, height, width]`）兼容的形状（`[batch_size, 1, 1, 1]`）。这使得时间 `t` 可以直接与图像张量 `x`进行广播运算。

#### 2. 路径规划器: `LinearPath`

这个类定义了最简单的一种路径：**线性插值路径**。

- `_compute_coeffs(self, t)`: 根据时间`t`计算线性插值的系数。在这里，`alpha_t = t`，`sigma_t = 1 - t`。它同时也计算了这些系数的导数（`d_alpha_t` 和 `d_sigma_t`），这对应于速度。
- `plan(self, t, x0, x1)`: 这是核心规划函数。
  - `xt = alpha_t * x1 + sigma_t * x0`: 计算在时间`t`的路径点，即真实图像`x1`和噪声`x0`的线性组合。
  - `ut = d_alpha_t * x1 + d_sigma_t * x0`: 计算在`t`时刻的**真实速度**。这是模型需要去拟合的目标。根据线性插值的公式，真实速度就是`x1 - x0`。

#### 3. 训练协调器: `Transport`

这个类是训练过程的“大脑”，它利用`LinearPath`来构建训练问题并计算损失。

- `__init__(self, train_eps=1e-5, sample_eps=1e-3)`: 初始化时设置了`train_eps`和`sample_eps`。这些小的`epsilon`值是为了避免在`t=0`或`t=1`这两个极端点进行计算，因为在这些点上ODE可能会变得不稳定（数值奇异性）。
- `_sample_time_and_noise(self, x1)`: 为每个训练样本`x1`准备一个随机的时间步`t`和一个随机噪声`x0`。
- `training_losses(self, model, x1, model_kwargs=None)`: 这是整个项目中最核心的函数之一，它完整地执行了一个训练步骤的损失计算。
  1. 调用 `_sample_time_and_noise` 获取随机的 `t` 和 `x0`。
  2. 调用 `self.path_sampler.plan` 获取在时间 `t` 的插值点 `xt` 和**真实的**速度 `true_velocity`。
  3. 将 `xt` 和 `t` (以及类别等其他条件 `model_kwargs`) 输入到 `model` 中，得到**模型预测的**速度 `predicted_velocity`。
  4. `loss = mean_flat((predicted_velocity - true_velocity) ** 2)`: 计算预测速度和真实速度之间的**均方误差（MSE）**作为损失。
  5. 返回包含损失的字典。 **这个损失值将用于反向传播，驱动模型去学习正确的速度场。**
- `_get_drift_function(self)`: 这是一个简单的辅助函数，它返回一个lambda函数，这个函数的作用就是直接调用模型本身。这个lambda函数就是我们ODE求解器中需要的“漂移函数”（drift function），即速度函数。

#### 4. ODE求解器和采样器

##### `ODESolver`

这是一个通用的ODE求解器封装类。

- 它接收一个 `drift_fn`（也就是我们模型学到的速度函数）。
- `sample(self, x, model, **model_kwargs)`: 这个方法调用了第三方库 `torchdiffeq` 中的 `odeint` 函数。
  - `odeint` 会从起点 `x` (一个随机噪声)，在时间 `self.t` (例如从0.001到0.999的50个步长)上进行积分。
  - 在每一步积分中，它都会调用 `_ode_func`，而 `_ode_func` 内部又会调用我们的模型 `self.drift_fn` 来获取当前位置和时间的速度。
  - 最终，`odeint` 返回整个路径的解，其中最后一个时间步的解就是我们生成的样本。

##### `Sampler`

`Sampler`类是将`Transport`和`ODESolver`连接起来的桥梁，专门用于生成图像。

- `__init__(self, transport: Transport)`: 它接收一个`Transport`实例，并从中获取学到的漂移函数（速度函数）。
- `get_sampler_fn(self, num_steps=50, atol=1e-6, rtol=1e-3)`: 这是一个工厂方法，它配置并返回一个随时可以使用的采样函数。
  1. 它根据配置参数（采样步数、容忍度等）实例化一个`ODESolver`。
  2. 它返回这个求解器的 `sample` 方法。在 `sample.py` 中，我们就是调用这个返回的 `sample_fn` 来执行完整的生成过程。



### train.py

#### **1. 准备工作**

- **环境设置**: 脚本首先会设置计算设备（优先使用 `cuda`，否则用 `cpu`）和随机种子，以确保实验的可复现性。
- **目录创建**: 它会自动创建用于保存模型检查点 (`checkpoints`) 和中间样本 (`samples`) 的文件夹，这是一个良好的工程实践。

#### **2. 初始化核心组件**

这是训练前最关键的准备阶段，脚本在这里集齐了所有必要的“神兵利器”。

- **创建 SiT 模型**: 通过调用 `models.py` 中的 `create_SiT_model` 函数来实例化一个 SiT 模型。模型的具体配置（如深度、隐藏层大小等）由 `config.py` 中的 `model` 字段决定。
- **创建 EMA 模型**: 脚本创建了一个名为 `ema` 的模型，它是主模型 `model` 的一个**深拷贝 (deepcopy)**。EMA (Exponential Moving Average, 指数移动平均) 模型在训练过程中，其参数会平滑地追踪主模型的参数更新。实践证明，在评估和生成时使用 EMA 模型的权重，通常能获得比直接使用主模型更稳定、更高质量的结果。`requires_grad(ema, False)` 确保了这个 EMA 模型本身不参与梯度计算，只被动地接收更新。
- **加载 VAE**: 脚本从 `diffusers` 库加载了一个预训练好的 `AutoencoderKL` (VAE) 模型。**这是 SiT 训练效率的关键**。SiT 并非直接在像素级别（如 256x256x3）上操作，而是在一个低维度的**潜在空间**（latent space，如 32x32x4）中进行。VAE 的编码器 (`encode`) 负责将高分辨率的真实图像压缩到这个潜在空间，而解码器 (`decode`) 则在生成结束后负责将潜在表示还原为图像。这极大地降低了计算量和内存消耗。
- **初始化 Transport**: `Transport` 类是 `transport.py` 的核心，它封装了 SiT 的训练逻辑。`train_eps=1e-5` 是为了防止在时间 `t` 接近 0 或 1 时可能出现的数值不稳定问题。

#### **3. 数据与优化器配置**

- **优化器**: 使用 `AdamW` 优化器，这是目前训练 Transformer 类模型的标准选择。学习率 `lr` 等参数从 `config.py` 读取。
- **数据预处理与加载**:
  - 定义了一个 `transforms.Compose` 流程，对输入的每一张图像进行处理。其中 `center_crop_arr` (来自 `utils.py`) 是一个高质量的中心裁剪函数，保证了输入尺寸的统一。`RandomHorizontalFlip` 是一种常见的数据增强手段。
  - 使用 `ImageFolder` 来读取用户在 `config.py` 中指定的 `data_path` 下的图像数据。
  - 最后用 `DataLoader` 将数据集包装成可以按批次 (`batch_size`) 加载的形式，`shuffle=True` 保证了训练时数据的随机性。

#### **4. 核心训练循环**

这是脚本中最重要的部分，模型在这里进行迭代学习。

- **外层循环** 遍历 `epochs` (总训练轮数)，**内层循环** 遍历 `DataLoader` 中的每一个批次数据 (`x`, `y`)。
- **编码至潜在空间**: `with torch.no_grad()` 上下文管理器确保 VAE 的编码过程不产生梯度。`x = vae.encode(x).latent_dist.sample().mul_(0.18215)` 这行代码将一批 RGB 图像 `x` 转换为潜在空间表示。`.mul_(0.18215)` 是一个经验性的缩放因子，用于匹配 VAE 的输出尺度。
- **计算损失**:
  - `model_kwargs = dict(y=y)` 将类别标签 `y` 包装起来，传递给模型用于条件生成。
  - `loss_dict = transport.training_losses(model, x, model_kwargs)` 是**训练的核心**。`transport` 对象会：
    1. 随机采样一个时间 `t` 和一个噪声 `x0`。
    2. 根据 `t`、`x0` 和真实的潜在图像 `x`（在此被视为 `x1`），计算出中间状态 `xt` 和真实的速度 `true_velocity`。
    3. 将 `xt`、`t` 和 `y` 送入 `model`，得到模型预测的速度 `predicted_velocity`。
    4. 计算 `true_velocity` 和 `predicted_velocity` 之间的均方误差（MSE），并作为损失返回。
- **优化步骤**: 这是标准的 PyTorch 训练流程。`opt.zero_grad()` 清除旧梯度，`loss.backward()` 计算新梯度，`opt.step()` 更新模型参数。
- **更新 EMA 模型**: 在每次主模型参数更新后，调用 `update_ema` 函数，平滑地更新 `ema` 模型的参数。
- **日志记录与保存**: 脚本会定期（每 100 步）打印当前的平均损失和训练速度，帮助研究者监控训练进程。并且会按照 `config.py` 中设定的 `ckpt_every` 步数，将模型、EMA模型和优化器的状态保存为一个检查点文件 (`.pt`)，以便后续可以从中断处恢复训练或直接用于采样。



### sample.py

#### **1. 准备工作**

与 `train.py` 类似，设置随机种子和设备，并关闭梯度计算 (`torch.set_grad_enabled(False)`)，因为采样过程只是前向传播，不需要反向传播和优化。

#### **2. 加载核心组件**

- **创建 SiT 模型**: 同样使用 `create_SiT_model` 创建模型结构。
- **加载预训练权重**:
  - `state_dict = find_model(args.ckpt)` 调用 `utils.py` 中的 `find_model` 函数。这个函数非常智能，如果 `args.ckpt` 是一个预定义的模型名，它会自动从网上下载；如果是一个本地路径，它会直接加载该文件。它还会自动检查检查点中是否包含 `ema` 权重，并优先使用 `ema` 权重，因为它们通常效果更好。
  - `model.load_state_dict(state_dict)` 将加载的权重应用到模型上。
  - `model.eval()` 将模型切换到**评估模式**，这会关闭 `dropout` 等只在训练时使用的层，确保生成结果的确定性。
- **初始化 Transport 和 Sampler**:
  - `transport = Transport(sample_eps=1e-3)` 初始化 `Transport` 对象。
  - `sampler = Sampler(transport)` 创建一个 `Sampler` 实例。`Sampler` 的作用是作为 `Transport` 和 `ODE` 求解器之间的桥梁。
  - `sample_fn = sampler.get_sampler_fn(...)` **获取最终的采样函数**。这个函数内部已经配置好了 `ODE` 求解器（`dopri5`），设定了积分的起始时间 `t0`、终止时间 `t1`、积分步数 `num_sampling_steps` 以及求解器的精度参数 `atol` 和 `rtol`。
- **加载 VAE**: 同样加载 `VAE`，但这次我们只需要它的 `decode` 功能，用于将生成的潜在表示还原为图像。

#### **3. 准备采样输入**

- **定义条件**: `class_labels` 列表定义了我们希望模型生成哪些类别的图像。`n` 是要生成的图像数量。
- **创建初始噪声**: `z = torch.randn(...)` 创建了一个与潜在空间维度匹配的**纯高斯噪声**张量。这是整个生成过程的起点。
- **实现无分类器指导 (Classifier-Free Guidance, CFG)**: 这是提升条件生成质量的关键技巧，代码实现非常经典。
  1. **复制输入**: 将初始噪声 `z` 复制一份并拼接起来，`z` 的大小变为 `2n`。
  2. **创建空条件**: `y_null` 是一个特殊的标签列表，其中的值（`num_classes`）指向 `LabelEmbedder` 中一个专门用于无条件生成的“空白”嵌入向量。
  3. **拼接条件**: 将真实的类别标签 `y` 和空标签 `y_null` 拼接起来。
  4. **设置模型函数**: `model_fn` 被设置为 `model.forward_with_cfg`。这个特殊的 `forward` 方法会接收拼接后的输入，在内部同时计算有条件（`cond_eps`）和无条件（`uncond_eps`）的预测结果，然后通过公式 `uncond_eps + cfg_scale * (cond_eps - uncond_eps)` 将两者融合，从而在保持多样性的同时，强化了生成内容与给定条件的匹配度。

#### **4. 执行采样与解码**

- **调用 ODE 求解器**: `samples_latent = sample_fn(z, model_fn, **model_kwargs)[-1]` 是**执行生成的命令**。
  - `sample_fn` (即 `odeint`) 会从初始噪声 `z` (t=0) 开始，以 `model_fn` (即带 CFG 的 SiT 模型) 作为速度场，进行常微分方程求解。
  - 它会返回所有时间步的解，`[-1]` 表示我们只取最后一个时间步（t=1）的结果，这就是最终生成的潜在空间样本。
- **处理 CFG 输出**: 如果使用了 CFG，`samples_latent` 的前半部分是带条件的结果，后半部分是无条件的结果。我们只需要前半部分，所以用 `.chunk(2, dim=0)` 将其分离出来。
- **解码为图像**: `with torch.no_grad()` 再次确保无梯度计算。`samples_image = vae.decode(samples_latent / 0.18215).sample` 调用 VAE 的解码器，将潜在样本 `samples_latent` 转换回我们可以看到的 RGB 图像。`/ 0.18215` 同样是用于匹配 VAE 尺度的逆缩放操作。
- **保存结果**: `save_image` 函数将生成的图像整齐地排列在一个网格中，并保存为指定的输出文件。