论文链接：[2401.08740](https://arxiv.org/pdf/2401.08740)

### Scalable Interpolant Transformers (SiT) 

本质上就是 DiT + Flow Matching

<img width="1803" height="1015" alt="image" src="https://github.com/user-attachments/assets/457015de-415d-4b7f-a167-b7740769f4a4" />

我们可以将SiT的原理理解为一个“三步走”的创新过程：
1.  **第一步：改进“路径”** - 引入“随机插值器”，找到一条从噪声到图像的更优“路径”。
2.  **第二步：学习“导航”** - 训练模型学习在这条新路径上如何“导航”（即学习速度场）。
3.  **第三步：选择“座驾”** - 使用强大的Transformer作为学习和导航的工具。

#### 第一步：改进“路径”——随机插值器（Stochastic Interpolants）

要理解SiT的创新，首先要明白传统扩散模型（如DDPM）的工作方式。

* **传统扩散模型的问题：** 它们像是在一条**固定且崎岖的山路**上行走。首先，它们通过一个固定的、一步步加噪的“前向过程”，把一张清晰的图像变成纯噪声。这个过程就像是强行把一个人从山脚（清晰图像）沿着一条预设的、复杂曲折的路上推到山顶（纯噪声）。然后，模型学习的是如何从山顶沿着原路精确地返回山脚。这条“山路”是固定的，不一定是最高效、最平坦的路径，这给模型的学习带来了不必要的困难。

* **SiT的解决方案——随机插值器：** SiT认为，我们不必局限于那条固定的山路。我们可以**自由地在山脚（数据）和山顶（噪声）之间建立一条更平滑、更直接的“直线缆车”**。这就是“插值器”的核心思想。

在数学上，这条“缆车路径”由一个简单的**插值方程**定义：

![x_t = \alpha_t \cdot x_1 + \sigma_t \cdot x_0](https://latex.codecogs.com/svg.latex?%5Cbg_white%20x_t%20%3D%20%5Calpha_t%20%5Ccdot%20x_1%20%2B%20%5Csigma_t%20%5Ccdot%20x_0)

让我们来解读这个公式：
* ![x_t](https://latex.codecogs.com/svg.latex?%5Cbg_white%20x_t)：表示在时间 ![\Large t](https://latex.codecogs.com/svg.latex?%5Cbg_white%20t) 时，介于噪声和图像之间的中间状态。
* ![x_1](https://latex.codecogs.com/svg.latex?%5Cbg_white%20x_1)：表示“山脚”，即一张真实的、清晰的图像数据。
* ![x_0](https://latex.codecogs.com/svg.latex?%5Cbg_white%20x_0)：表示“山顶”，即一个纯粹的随机噪声样本（通常是高斯噪声）。
* ![\Large t](https://latex.codecogs.com/svg.latex?%5Cbg_white%20t)：时间变量，通常从0到1。![t=0](https://latex.codecogs.com/svg.latex?%5Cbg_white%20t%3D0) 时是纯噪声，![t=1](https://latex.codecogs.com/svg.latex?%5Cbg_white%20t%3D1) 时是清晰图像（或者反过来，不同论文定义可能不同，但原理一致）。
* ![\alpha_t](https://latex.codecogs.com/svg.latex?%5Cbg_white%20%5Calpha_t) 和 ![\sigma_t](https://latex.codecogs.com/svg.latex?%5Cbg_white%20%5Csigma_t)：这是两个随时间 ![\Large t](https://latex.codecogs.com/svg.latex?%5Cbg_white%20t) 变化的**“混合系数”**。你可以把 ![\alpha_t](https://latex.codecogs.com/svg.latex?%5Cbg_white%20%5Calpha_t) 想象成“数据”的权重，![\sigma_t](https://latex.codecogs.com/svg.latex?%5Cbg_white%20%5Csigma_t) 想象成“噪声”的权重。随着 ![\Large t](https://latex.codecogs.com/svg.latex?%5Cbg_white%20t) 从0到1，![\alpha_t](https://latex.codecogs.com/svg.latex?%5Cbg_white%20%5Calpha_t) 会变大，![\sigma_t](https://latex.codecogs.com/svg.latex?%5Cbg_white%20%5Csigma_t) 会变小，使得 ![x_t](https://latex.codecogs.com/svg.latex?%5Cbg_white%20x_t) 从一个纯噪声点平滑地过渡到一个清晰的数据点。

**核心优势在于“解耦”和“灵活性”**：
SiT最大的突破在于，![\alpha_t](https://latex.codecogs.com/svg.latex?%5Cbg_white%20%5Calpha_t) 和 ![\sigma_t](https://latex.codecogs.com/svg.latex?%5Cbg_white%20%5Csigma_t) 的选择非常灵活，它们不再与一个固定的随机微分方程（SDE）绑定。研究者可以选择最简单的**线性插值**（![\alpha_t = t, \sigma_t = 1-t](https://latex.codecogs.com/svg.latex?%5Cbg_white%20%5Calpha_t%20%3D%20t%2C%20%5Csigma_t%20%3D%201-t)），这就像是修建了一条笔直的路径。这种路径比传统扩散模型的“曲折山路”更简单、曲率更低，因此模型学习起来也更容易，最终的生成效果也更好。

#### 第二步：学习“导航”——学习速度场（Velocity Field）

确定了这条更优的“路径”后，接下来的问题是：模型如何学习沿着这条路径从噪声走向图像？

答案是学习一个**速度场（Velocity Field）**，可以理解为学习在路径上每一点的“前进方向和速度”。

* **速度场 ![v(x_t, t)](https://latex.codecogs.com/svg.latex?%5Cbg_white%20v(x_t%2C%20t))**：它描述了在时间 ![t](https://latex.codecogs.com/svg.latex?%5Cbg_white%20t)，当状态为 ![x_t](https://latex.codecogs.com/svg.latex?%5Cbg_white%20x_t) 时，为了向清晰图像 ![x_1](https://latex.codecogs.com/svg.latex?%5Cbg_white%20x_1) 移动，下一步应该朝哪个方向走、走多快。
* **学习目标**：SiT模型的核心任务不再是像传统扩散模型那样预测噪声，而是直接学习这个速度场。它会训练一个神经网络 ![v_\theta(x_t, t)](https://latex.codecogs.com/svg.latex?%5Cbg_white%20v_%5Ctheta(x_t%2C%20t)) 去逼近真实的速度场 ![v(x_t, t)](https://latex.codecogs.com/svg.latex?%5Cbg_white%20v(x_t%2C%20t))。这个学习目标通常是一个简单的均方误差损失函数（MSE Loss），非常直观且高效。
* **生成过程（采样）**：一旦模型 ![v_\theta](https://latex.codecogs.com/svg.latex?%5Cbg_white%20v_%5Ctheta) 学会了这个“导航图”，生成一张新图像就变得很简单了：
    1.  从随机噪声 ![x_0](https://latex.codecogs.com/svg.latex?%5Cbg_white%20x_0) 出发。
    2.  利用学习到的速度场 ![v_\theta](https://latex.codecogs.com/svg.latex?%5Cbg_white%20v_%5Ctheta)，通过求解一个常微分方程（ODE）来一步步更新状态：![dx/dt = v_\theta(x, t)](https://latex.codecogs.com/svg.latex?%5Cbg_white%20dx%2Fdt%20%3D%20v_%5Ctheta(x%2C%20t))。
    3.  这个过程就像是启动了一辆自动驾驶汽车，它会根据导航图（学习到的速度场）自动从噪声的山顶开到数据的山脚，最终得到一张清晰的图像。

此外，SiT还可以在这个采样过程中加入可控的随机性（变成SDE采样），这有时能进一步提升生成样本的多样性和质量。这种采样器的可调性也是其灵活性的一大体现。

#### 第三步：选择“座驾”—— Transformer

路径和导航方法都确定了，现在需要一个强大的“引擎”或“座驾”来执行这个学习任务。SiT选择了**Transformer**，继承自其前身DiT（Diffusion Transformer）。

为什么是Transformer，而不是像传统扩散模型中常用的U-Net？

1.  **卓越的可扩展性（Scalability）**：这是最关键的原因。研究已经证明，Transformer架构具有惊人的可扩展性。只要增加模型的计算量——无论是通过增加模型的深度/宽度，还是通过将图像切成更小的块（Patches）来增加输入序列的长度——模型的性能（如生成图像的FID分数）几乎总能稳定地提升。这使得构建更大、更强的生成模型成为可能。
2.  **全局依赖建模能力**：Transformer的自注意力机制（Self-Attention）使其能够高效地捕捉图像中任意两个区域之间的长距离依赖关系。这对于生成结构复杂、内容协调的图像至关重要。
3.  **高效的条件注入**：SiT沿用了DiT中的`adaLN`（Adaptive Layer Normalization）等技术。这种技术可以非常有效地将时间 ![\Large t](https://latex.codecogs.com/svg.latex?%5Cbg_white%20t) 和类别标签等“条件信息”融入到Transformer的每一层中。这相当于告诉“座驾”，当前在路径的什么位置，以及最终的目标是什么（比如生成一只猫还是一辆车），从而精确地指导整个生成过程。


